{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageOps\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join\n",
    "from sklearn import svm, model_selection, datasets\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "%matplotlib notebook\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.image as mpimg\n",
    "import imageio as im\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensión de las imágenes\n",
    "img_width, img_height = 100,100\n",
    "\n",
    "#ruta de las imágenes\n",
    "train_data_dir = 'dataset/train'\n",
    "validation_data_dir = 'dataset/test'\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "\n",
    "#Se puede disminuir las épocas para una prueba más rápida\n",
    "#Podría demorar 1 minuto por época aproximadamente\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTO ES PARA SALVAR LAS IMÁGENES CON LAS NUEVAS DIMENSIONES\n",
    "#ruta = \"dataset/train\"\n",
    "#newdir = \"resizeImages\"\n",
    "#mkdir(newdir)\n",
    "\n",
    "#def ls(ruta):\n",
    "#    return [arch for arch in listdir(ruta) if isfile(join(ruta, arch))]\n",
    "\n",
    "#def resized(origen, destino,ancho,largo):\n",
    "    \n",
    "#    for name in ls(origen):\n",
    "\n",
    "        #print (name)\n",
    "        #imagen = Image.open(origen+\"/\"+name)\n",
    "        #new_image = imagen.resize((ancho, largo))\n",
    "        #new_image.save(destino+\"/\"+\"resized_\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized(ruta, newdir, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 438,369\n",
      "Trainable params: 438,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ESTRUCTURA INICIAL, parámetros temporales\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4035 images belonging to 2 classes.\n",
      "Found 996 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Compilación\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics =['accuracy'])\n",
    "\n",
    "#Creación del DataSET a partir de las imágenes en la carpeta dataset\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#REESCALADO\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Conjunto de datos y etiquetas para ENTRENAMIENTO\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Conjunto de datos y etiquetas para VALIDACIÓN\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30/31 [============================>.] - ETA: 14s - loss: 0.6498 - accuracy: 0.6125\n",
      "Epoch 00001: val_loss improved from inf to 0.50173, saving model to early.h5\n",
      "31/31 [==============================] - 450s 15s/step - loss: 0.6479 - accuracy: 0.6169 - val_loss: 0.5017 - val_accuracy: 0.8164\n",
      "Epoch 2/30\n",
      "30/31 [============================>.] - ETA: 1s - loss: 0.3979 - accuracy: 0.8451\n",
      "Epoch 00002: val_loss improved from 0.50173 to 0.40323, saving model to early.h5\n",
      "31/31 [==============================] - 65s 2s/step - loss: 0.3977 - accuracy: 0.8461 - val_loss: 0.4032 - val_accuracy: 0.8255\n",
      "Epoch 3/30\n",
      "30/31 [============================>.] - ETA: 2s - loss: 0.3236 - accuracy: 0.8766\n",
      "Epoch 00003: val_loss improved from 0.40323 to 0.26982, saving model to early.h5\n",
      "31/31 [==============================] - 76s 2s/step - loss: 0.3235 - accuracy: 0.8765 - val_loss: 0.2698 - val_accuracy: 0.9167\n",
      "Epoch 4/30\n",
      "30/31 [============================>.] - ETA: 1s - loss: 0.3005 - accuracy: 0.8870\n",
      "Epoch 00004: val_loss improved from 0.26982 to 0.21371, saving model to early.h5\n",
      "31/31 [==============================] - 67s 2s/step - loss: 0.2982 - accuracy: 0.8872 - val_loss: 0.2137 - val_accuracy: 0.9219\n",
      "Epoch 5/30\n",
      "30/31 [============================>.] - ETA: 2s - loss: 0.2235 - accuracy: 0.9203\n",
      "Epoch 00005: val_loss improved from 0.21371 to 0.19330, saving model to early.h5\n",
      "31/31 [==============================] - 75s 2s/step - loss: 0.2228 - accuracy: 0.9204 - val_loss: 0.1933 - val_accuracy: 0.9167\n",
      "Epoch 6/30\n",
      "30/31 [============================>.] - ETA: 1s - loss: 0.2134 - accuracy: 0.9198\n",
      "Epoch 00006: val_loss improved from 0.19330 to 0.16158, saving model to early.h5\n",
      "31/31 [==============================] - 68s 2s/step - loss: 0.2165 - accuracy: 0.9184 - val_loss: 0.1616 - val_accuracy: 0.9297\n",
      "Epoch 7/30\n",
      "28/31 [==========================>...] - ETA: 6s - loss: 0.1777 - accuracy: 0.9247"
     ]
    }
   ],
   "source": [
    "epochs_to_wait_for_improve = 2\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \n",
    "                                        patience=epochs_to_wait_for_improve)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('early.h5', \n",
    "                                      monitor='val_loss', \n",
    "                                      verbose=1, \n",
    "                                      save_best_only=True, \n",
    "                                      mode='min')\n",
    "\n",
    "\n",
    "#Entrenamiento\n",
    "start_time = time()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=[early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "# Salvado de pesos como archivo\n",
    "model.save_weights('estructura_1.h5')\n",
    "\n",
    "elapsed_time = time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "holdout_gen = ImageDataGenerator(rescale = 1/255)\n",
    "holdout = holdout_gen.flow_from_directory(train_data_dir,\n",
    "                                    shuffle=False,\n",
    "                                    batch_size=50,\n",
    "                                    class_mode='binary')\n",
    "\n",
    "#model_eval = model.predict_generator(holdout, use_multiprocessing=True)\n",
    "\n",
    "#preds = pd.DataFrame(model_eval, columns = holdout.class_indices.keys())\n",
    "#preds['filename'] = holdout.filenames\n",
    "#preds['truth'] = preds['filename'].apply(os.path.dirname)\n",
    "#preds['predicted_class'] = preds[list(holdout.class_indices.keys())].idxmax(1)\n",
    "#preds.head()\n",
    "\n",
    "\n",
    "#print(str(np.mean(preds['predicted_class'] == preds['truth']) * 100) + \"% Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curva aciertos en épocas \n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "evaluation = model.evaluate_generator(train_generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ENTRENAMIENTO & VALIDACI accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot ENTRENAMIENTO & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_path = 'dataset/test/freshapples/rotated_by_15_Screen Shot 2018-06-08 at 4.59.49 PM.png'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(100, 100))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()\n",
    "\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.expand_dims(image, axis=0) #para agregar una dimensión extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers[:5]] # Extrae los resultados de las 5 capas superiores.\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Crea un modelo que devolverá las salidas, dada la entrada del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_tensor) # Devuelve una lista de cinco matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [model]\n",
    "for layer in model.layers[:12]:\n",
    "    layer_names.append(layer.name) # nombre de las capas\n",
    "    \n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Muestra los mapas de características\n",
    "    n_features = layer_activation.shape[-1] # Número de características en el mapa de características\n",
    "    size = layer_activation.shape[1]\n",
    "    n_cols = n_features // images_per_row # Mosaicos de los canales de activación en esta matriz\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): #Coloca cada filtro en una cuadrícula horizontal\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean() # Post-procesa la función para que sea visualmente agradable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truths(df, class_label):\n",
    "    y_truth = df['truth'] == class_label\n",
    "    return y_truth.astype(int).values, df[class_label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
